{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils import data\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from  numpy import exp, absolute, asarray\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time, os, json, random, gc, copy, math, multiprocessing\n",
    "from sklearn import svm\n",
    "import sklearn.model_selection as model_selection\n",
    "from sklearn.metrics import accuracy_score,f1_score,precision_score ,recall_score \n",
    "from PIL import Image\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from pathlib import Path\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = str(Path().resolve().parent.parent.parent) + \"/Datasets/Validation Datasets/DIP/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 128\n",
    "STRIDE = 64\n",
    "img_path = data_path\n",
    "HO_P_list = os.listdir(img_path + \"positiveLR/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "HO_dict = {}\n",
    "HO_data = []\n",
    "HO_label = []\n",
    "orig_y_HO = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(image, stride, imgSize):\n",
    "    height, width, _ = image.shape\n",
    "    img = []\n",
    "    a1 = list(range(0, height-imgSize+stride, stride))\n",
    "    a2 = list(range(0, width-imgSize+stride, stride))\n",
    "    if (a1[-1]+imgSize != height):\n",
    "        a1[-1] = height-imgSize\n",
    "    if (a2[-1]+imgSize != width):\n",
    "        a2[-1] = width-imgSize\n",
    "    for y in a1:\n",
    "        for x in a2:\n",
    "            im1 = image[y:y+imgSize, x:x+imgSize, :]\n",
    "            img.append(np.array(im1))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_one_image(path, sType):\n",
    "    image_data = []\n",
    "    im = Image.open(path)\n",
    "    im = im.convert('RGB')\n",
    "    im = np.array(im)\n",
    "    if (im.shape[0] >= SIZE and im.shape[1] >= SIZE):\n",
    "        img = sliding_window(im, STRIDE, SIZE)\n",
    "        for i in range(len(img)):\n",
    "            if(img[i].shape[2] >=3):\n",
    "                image_data.append(img[i])\n",
    "        return image_data, sType\n",
    "    else:\n",
    "        # indicate that no images are available\n",
    "        return [], sType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_parallel_HO():\n",
    "    print(\"Applying sliding windows to Held out data\")\n",
    "    global HO_data\n",
    "    global HO_label\n",
    "    global HO_dict\n",
    "    global orig_y_HO\n",
    "    global image\n",
    "    # Create a list of tuples consisting of the file path, and the class\n",
    "    # dictionary info for each of the cl arguments\n",
    "    args = []\n",
    "    for img_file in HO_P_list:\n",
    "        path = img_path +\"/positiveLR/\"+img_file\n",
    "        im = Image.open(path)\n",
    "        im = im.convert('RGB')\n",
    "        im = np.array(im)\n",
    "        if (im.shape[0] >= SIZE and im.shape[1] >= SIZE):\n",
    "            args.append((path, 1))\n",
    "            orig_y_HO.append(1)\n",
    "            \n",
    "    num_workers = multiprocessing.cpu_count()  \n",
    "\n",
    "    with multiprocessing.Pool(processes = num_workers) as pool:   # or however many processes\n",
    "        subimage_counter = 0\n",
    "        origimage_counter = 0\n",
    "        # Use multiprocessing to call handle_on_image(pathname, info)\n",
    "        # and return the results in order\n",
    "        for images, info in pool.starmap(handle_one_image, args):\n",
    "            image_list = []\n",
    "            # Images is a list of returned images.  info is the class_dictionary info that we passed\n",
    "            for image in images:\n",
    "                image_list.append(subimage_counter)\n",
    "                subimage_counter += 1\n",
    "                HO_data.append(image)\n",
    "                HO_label.append(info)\n",
    "            HO_dict[origimage_counter] = image_list\n",
    "            origimage_counter += 1\n",
    "    print(\"Sliding window process finished for HO data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying sliding windows to Held out data\n",
      "Sliding window process finished for HO data\n"
     ]
    }
   ],
   "source": [
    "sub_parallel_HO()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "HO_data = np.array(HO_data)\n",
    "HO_label = np.array(HO_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47205, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "print(HO_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47205, 3, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "HO_data = np.moveaxis(HO_data, 3, 1)\n",
    "print(HO_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(str(Path().resolve().parent.parent) + \"/Benchmark/PanEtAl/\" + \"finalmodel-full.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_x = torch.Tensor(HO_data) # transform to torch tensor\n",
    "tensor_y = torch.Tensor(HO_label)\n",
    "\n",
    "my_dataset = TensorDataset(tensor_x,tensor_y) # create your datset\n",
    "holoader = DataLoader(my_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-4, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.000.. Test accuracy: 1.000\n"
     ]
    }
   ],
   "source": [
    "ho_loss = 0\n",
    "ho_accuracy = 0\n",
    "res = []\n",
    "orig_labels = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in holoader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.type(torch.LongTensor) # <---- Here (casting)\n",
    "        labels = labels.to(device)\n",
    "        logps = model.forward(inputs)\n",
    "        batch_loss = criterion(logps, labels)\n",
    "        ho_loss += batch_loss.item()\n",
    "\n",
    "        ps = torch.exp(logps)\n",
    "        top_p, top_class = ps.topk(1, dim=1)\n",
    "        equals = top_class == labels.view(*top_class.shape)\n",
    "        res.extend(top_class)\n",
    "        orig_labels.extend(labels)\n",
    "        ho_accuracy += torch.mean(equals.type(torch.FloatTensor)).item()                \n",
    "print(f\"Test loss: {ho_loss/len(holoader):.3f}.. \"\n",
    "      f\"Test accuracy: {ho_accuracy/len(holoader):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred_float_thresh = []\n",
    "for img, subimage in HO_dict.items():\n",
    "    if isinstance(subimage, int):\n",
    "        final_pred_float_thresh.append(1 if subimage>=0.5 else 0)\n",
    "    else:\n",
    "        mean_ax1 = np.mean([res[x - 1].item() for x in subimage])\n",
    "        final_pred_float_thresh.append(1 if mean_ax1>=0.5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "correct = (np.array(final_pred_float_thresh) == np.array(orig_y_HO))\n",
    "accuracy = correct.sum() / correct.size\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
